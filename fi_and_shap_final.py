# -*- coding: utf-8 -*-
"""FI_and_SHAP_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WRIyV_kl5PBmA3_yS41rrBI2k4lT5tKN
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.inspection import permutation_importance
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, mean_squared_error, classification_report
from sklearn.impute import KNNImputer
from google.colab import drive

drive.mount('/content/drive')

"""#filter for 2017-2022"""

DIR = '/content/drive/MyDrive/Risk_Analysis_DINS/data/'#Maryam
filename = 'dins_all_mv.pkl'

df = pd.read_pickle(DIR + filename)

df= df[
    # Keep >= 2017 and Fire hazard type
    (df['INCIDENTSTARTDATE'] >= '2017-01-01')
]

df.to_csv("dins_2017_2022.csv")

DIR = '/content/drive/MyDrive/Risk_Analysis_DINS/dins_all/data/'#Maryam

df=pd.read_csv(DIR+'dins_2017_2022.csv')

#df=df.drop(['field_1','STREETTYPE','STREETSUFF','CALFIREUNI','COUNTY','BATTALION',
            'INCIDENTNA','INCIDENTNU','INCIDENTST','WHEREFIRES','WHATDIDFIR','DEFENSIVEA',
            'STRUCTURET','STRUCTUREC','NUMBEROFUN','NOOUTBUILD','NOOUTBUI_1','PROPANETAN','UTILITYMIS',
            'APN','ASSESSEDIM','Distance_meter', 'Latitude','Longitude'], axis=1)

df1 = {
    'DAMAGE': 'DAMAGE',
    'ROOFCONSTR': 'Roof Construction',
    'EAVES': 'Eaves',
    'VENTSCREEN': 'Vent Screen',
    'EXTERIORSI': 'Exterior Siding',
    'WINDOWPANE': 'Window Pane',
    'Distance': 'Distance',
    'DECKPORCHO':'Deck/Porch on Grade',
    'DECKPORCHE': 'Deck/Porch Elevated',
    'PATIOCOVER': 'Patio Cover',
    'FENCEATTAC': 'Fence',
    'YEARBUILT':'YEARBUILT',
}

# Use the rename method to change column names
df.rename(columns=df1, inplace=True)

print(df)

"""#filter for 2021-2022"""

DIR = '/content/drive/MyDrive/Risk_Analysis_DINS/data/'#Maryam
filename = 'dins_all_mv.pkl'

df = pd.read_pickle(DIR + filename)

df= df[
    # Keep >= 2021 and Fire hazard type
    (df['INCIDENTSTARTDATE'] >= '2021-01-01')
]

df.to_csv("dins_2021_2022.csv")

DIR = '/content/drive/MyDrive/Risk_Analysis_DINS/dins_all/data/'#Maryam

df=pd.read_csv(DIR+'dins_2021_2022.csv')

list(df.columns)

df=df.drop(['field_1','STREETTYPE','STREETSUFF','CALFIREUNI','COUNTY','BATTALION',
            'INCIDENTNA','INCIDENTNU','INCIDENTST','WHEREFIRES','WHATDIDFIR','DEFENSIVEA',
            'STRUCTURET','STRUCTUREC','NUMBEROFUN','NOOUTBUILD','NOOUTBUI_1','PROPANETAN','UTILITYMIS',
            'APN','ASSESSEDIM','Distance_meter', 'Latitude','Longitude'], axis=1)

df1 = {
    'DAMAGE': 'DAMAGE',
    'ROOFCONSTR': 'Roof Construction',
    'EAVES': 'Eaves',
    'VENTSCREEN': 'Vent Screen',
    'EXTERIORSI': 'Exterior Siding',
    'WINDOWPANE': 'Window Pane',
    'Distance': 'Distance',
    'DECKPORCHO':'Deck/Porch on Grade',
    'DECKPORCHE': 'Deck/Porch Elevated',
    'PATIOCOVER': 'Patio Cover',
    'FENCEATTAC': 'Fence',
    'YEARBUILT':'YEARBUILT',
}

# Use the rename method to change column names
df.rename(columns=df1, inplace=True)

print(df)

"""#filter by year

for 2017
"""

DIR = '/content/drive/MyDrive/Risk_Analysis_DINS/data/'#Maryam
filename = 'dins_all_mv.pkl'

df = pd.read_pickle(DIR + filename)

df = df[
    # Keep dates > 2017-01-01 and < 2017-12-30
    (df['INCIDENTSTARTDATE'] > '2017-01-01') & (df['INCIDENTSTARTDATE'] < '2017-12-30')
]

df.to_csv("dins_2017.csv")

DIR = '/content/drive/MyDrive/Risk_Analysis_DINS/dins_all/data/'#Maryam

df=pd.read_csv(DIR+'dins_2017.csv')

list(df.columns)

df=df.drop(['field_1','STREETTYPE','STREETSUFF','CALFIREUNI','COUNTY','BATTALION',
            'INCIDENTNA','INCIDENTNU','INCIDENTST','WHEREFIRES','WHATDIDFIR','DEFENSIVEA',
            'STRUCTURET','STRUCTUREC','NUMBEROFUN','NOOUTBUILD','NOOUTBUI_1','PROPANETAN','UTILITYMIS',
            'APN','ASSESSEDIM','DECKPORCHO','DECKPORCHE','PATIOCOVER','FENCEATTAC','distance_meter','Latitude','Longitude'], axis=1)

df1 = {
    'DAMAGE': 'DAMAGE',
    'ROOFCONSTR': 'Roof Construction',
    'EAVES': 'Eaves',
    'VENTSCREEN': 'Vent Screen',
    'EXTERIORSI': 'Exterior Siding',
    'WINDOWPANE': 'Window Pane',
    'Distance': 'Distance',
    'YEARBUILT':'YEARBUILT',
}

# Use the rename method to change column names
df.rename(columns=df1, inplace=True)

print(df)

"""for 2018"""

DIR = '/content/drive/MyDrive/Risk_Analysis_DINS/data/'#Maryam
filename = 'dins_all_mv.pkl'

df = pd.read_pickle(DIR + filename)

df = df[
    # Keep dates > 2018-01-01 and < 2018-12-30
    (df['INCIDENTSTARTDATE'] > '2018-01-01') & (df['INCIDENTSTARTDATE'] < '2018-12-30')
]

df.to_csv("dins_2018.csv")

DIR = '/content/drive/MyDrive/Risk_Analysis_DINS/dins_all/data/'#Maryam

df=pd.read_csv(DIR+'dins_2018.csv')

list(df.columns)

df=df.drop(['field_1','STREETTYPE','STREETSUFF','CALFIREUNI','COUNTY','BATTALION',
            'INCIDENTNA','INCIDENTNU','INCIDENTST','WHEREFIRES','WHATDIDFIR','DEFENSIVEA',
            'STRUCTURET','STRUCTUREC','NUMBEROFUN','NOOUTBUILD','NOOUTBUI_1','PROPANETAN','UTILITYMIS',
            'APN','ASSESSEDIM','Distance_meter','Latitude','Longitude'], axis=1)

df1 = {
    'DAMAGE': 'DAMAGE',
    'ROOFCONSTR': 'Roof Construction',
    'EAVES': 'Eaves',
    'VENTSCREEN': 'Vent Screen',
    'EXTERIORSI': 'Exterior Siding',
    'WINDOWPANE': 'Window Pane',
    'Distance': 'Distance',
    'DECKPORCHO':'Deck/Porch on Grade',
    'DECKPORCHE': 'Deck/Porch Elevated',
    'PATIOCOVER': 'Patio Cover',
    'FENCEATTAC': 'Fence',
    'YEARBUILT':'YEARBUILT',
}

# Use the rename method to change column names
df.rename(columns=df1, inplace=True)

print(df)

"""for 2019"""

DIR = '/content/drive/MyDrive/Risk_Analysis_DINS/data/'#Maryam
filename = 'dins_all_mv.pkl'

df = pd.read_pickle(DIR + filename)

df = df[
    # Keep dates > 2019-01-01 and < 2019-12-30
    (df['INCIDENTSTARTDATE'] > '2019-01-01') & (df['INCIDENTSTARTDATE'] < '2019-12-30')
]

df.to_csv("dins_2019.csv")

DIR = '/content/drive/MyDrive/Risk_Analysis_DINS/dins_all/data/'#Maryam

df=pd.read_csv(DIR+'dins_2019.csv')

list(df.columns)

df=df.drop(['field_1','STREETTYPE','STREETSUFF','CALFIREUNI','COUNTY','BATTALION',
            'INCIDENTNA','INCIDENTNU','INCIDENTST','WHEREFIRES','WHATDIDFIR','DEFENSIVEA',
            'STRUCTURET','STRUCTUREC','NUMBEROFUN','NOOUTBUILD','NOOUTBUI_1','PROPANETAN','UTILITYMIS',
            'APN','ASSESSEDIM','Distance_meter','Latitude','Longitude'], axis=1)

df1 = {
    'DAMAGE': 'DAMAGE',
    'ROOFCONSTR': 'Roof Construction',
    'EAVES': 'Eaves',
    'VENTSCREEN': 'Vent Screen',
    'EXTERIORSI': 'Exterior Siding',
    'WINDOWPANE': 'Window Pane',
    'Distance': 'Distance',
    'DECKPORCHO':'Deck/Porch on Grade',
    'DECKPORCHE': 'Deck/Porch Elevated',
    'PATIOCOVER': 'Patio Cover',
    'FENCEATTAC': 'Fence',
    'YEARBUILT':'YEARBUILT',
}

# Use the rename method to change column names
df.rename(columns=df1, inplace=True)

print(df)

"""for 2020"""

DIR = '/content/drive/MyDrive/Risk_Analysis_DINS/data/'#Maryam
filename = 'dins_all_mv.pkl'

df = pd.read_pickle(DIR + filename)

df = df[
    # Keep dates > 2020-01-01 and < 2020-12-30
    (df['INCIDENTSTARTDATE'] > '2020-01-01') & (df['INCIDENTSTARTDATE'] < '2020-12-30')
]

df.to_csv("dins_2020.csv")

DIR = '/content/drive/MyDrive/Risk_Analysis_DINS/dins_all/data/'#Maryam

df=pd.read_csv(DIR+'dins_2020.csv')

list(df.columns)

df=df.drop(['field_1','STREETTYPE','STREETSUFF','CALFIREUNI','COUNTY','BATTALION',
            'INCIDENTNA','INCIDENTNU','INCIDENTST','WHEREFIRES','WHATDIDFIR','DEFENSIVEA',
            'STRUCTURET','STRUCTUREC','NUMBEROFUN','NOOUTBUILD','NOOUTBUI_1','PROPANETAN','UTILITYMIS',
            'APN','ASSESSEDIM','Distance_meter','Latitude','Longitude'], axis=1)

df1 = {
    'DAMAGE': 'DAMAGE',
    'ROOFCONSTR': 'Roof Construction',
    'EAVES': 'Eaves',
    'VENTSCREEN': 'Vent Screen',
    'EXTERIORSI': 'Exterior Siding',
    'WINDOWPANE': 'Window Pane',
    'Distance': 'Distance',
    'DECKPORCHO':'Deck/Porch on Grade',
    'DECKPORCHE': 'Deck/Porch Elevated',
    'PATIOCOVER': 'Patio Cover',
    'FENCEATTAC': 'Fence',
    'YEARBUILT':'YEARBUILT',
}

# Use the rename method to change column names
df.rename(columns=df1, inplace=True)

print(df)

"""2021"""

DIR = '/content/drive/MyDrive/Risk_Analysis_DINS/dins_all/data/'#Maryam

df=pd.read_csv(DIR+'dins_2021.csv')

list(df.columns)

df=df.drop(['field_1','STREETTYPE','STREETSUFF','CALFIREUNI','COUNTY','BATTALION',
            'INCIDENTNA','INCIDENTNU','INCIDENTST','WHEREFIRES','WHATDIDFIR','DEFENSIVEA',
            'STRUCTURET','STRUCTUREC','NUMBEROFUN','NOOUTBUILD','NOOUTBUI_1','PROPANETAN','UTILITYMIS',
            'APN','ASSESSEDIM','Distance_meter', 'Latitude','Longitude'], axis=1)

df1 = {
    'DAMAGE': 'DAMAGE',
    'ROOFCONSTR': 'Roof Construction',
    'EAVES': 'Eaves',
    'VENTSCREEN': 'Vent Screen',
    'EXTERIORSI': 'Exterior Siding',
    'WINDOWPANE': 'Window Pane',
    'Distance': 'Distance',
    'DECKPORCHO':'Deck/Porch on Grade',
    'DECKPORCHE': 'Deck/Porch Elevated',
    'PATIOCOVER': 'Patio Cover',
    'FENCEATTAC': 'Fence',
    'YEARBUILT':'YEARBUILT',
}

# Use the rename method to change column names
df.rename(columns=df1, inplace=True)

print(df)

"""2022"""

DIR = '/content/drive/MyDrive/Risk_Analysis_DINS/dins_all/data/'#Maryam

df=pd.read_csv(DIR+'dins_2022.csv')

list(df.columns)

df=df.drop(['field_1','STREETTYPE','STREETSUFF','CALFIREUNI','COUNTY','BATTALION',
            'INCIDENTNA','INCIDENTNU','INCIDENTST','WHEREFIRES','WHATDIDFIR','DEFENSIVEA',
            'STRUCTURET','STRUCTUREC','NUMBEROFUN','NOOUTBUILD','NOOUTBUI_1','PROPANETAN','UTILITYMIS',
            'APN','ASSESSEDIM','Distance_meter','Latitude','Longitude'], axis=1)

df1 = {
    'DAMAGE': 'DAMAGE',
    'ROOFCONSTR': 'Roof Construction',
    'EAVES': 'Eaves',
    'VENTSCREEN': 'Vent Screen',
    'EXTERIORSI': 'Exterior Siding',
    'WINDOWPANE': 'Window Pane',
    'Distance': 'Distance',
    'DECKPORCHO':'Deck/Porch on Grade',
    'DECKPORCHE': 'Deck/Porch Elevated',
    'PATIOCOVER': 'Patio Cover',
    'FENCEATTAC': 'Fence',
}

# Use the rename method to change column names
df.rename(columns=df1, inplace=True)

print(df)

"""#Correlation Matrix"""

corr_matrix = df.corr()

corr_matrix

cols = corr_matrix.columns
plt.figure(figsize=(10, 10),)
plt.matshow(corr_matrix, fignum=1)
plt.xticks(range(len(cols)), cols, rotation='vertical', fontsize=14)
plt.yticks(range(len(cols)), cols, fontsize=14)
plt.colorbar()
plt.show()

#np.sort(df['INCIDENTNAME'].unique())

#df= df[
    # Keep >= 2017 and Fire hazard type
    #(df['INCIDENTSTARTDATE'] >= '2017-01-01')
#]

"""#Feature Importance with Standard Scaling"""

DIR = '/content/drive/MyDrive/Risk_Analysis_DINS/dins_all/data/'

path_to_file = DIR + 'df.csv'

df = pd.read_csv(path_to_file)

list(df.columns)

import pandas as pd
import numpy as np
from sklearn.impute import KNNImputer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.inspection import permutation_importance
import matplotlib.pyplot as plt

# Data imputation
imputer = KNNImputer(n_neighbors=1)
imp_X = imputer.fit_transform(df)
df_X_imp = pd.DataFrame(imp_X, columns=df.columns)

# Data splitting
X = df_X_imp.drop('Damage', axis=1)
y = df_X_imp['Damage']
columns = X.columns

# Apply standard scaling to input features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=666)

# Model training and getting importance scores
model_lr = LinearRegression()
model_lr.fit(X_train, y_train)
importance_lr = model_lr.coef_
lr_pi = permutation_importance(model_lr, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2)
lr_pi_importances = pd.Series(lr_pi.importances_mean, index=columns)

model_dt = DecisionTreeRegressor(random_state=666)
model_dt.fit(X_train, y_train)
importance_dt = model_dt.feature_importances_
dt_pi = permutation_importance(model_dt, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2)
dt_pi_importances = pd.Series(dt_pi.importances_mean, index=columns)

model_rf = RandomForestRegressor(random_state=666)
model_rf.fit(X_train, y_train)
importance_rf = model_rf.feature_importances_
rf_pi = permutation_importance(model_rf, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2)
rf_pi_importances = pd.Series(rf_pi.importances_mean, index=columns)

model_gb = GradientBoostingRegressor(random_state=666)
model_gb.fit(X_train, y_train)
importance_gb = model_gb.feature_importances_
gb_pi = permutation_importance(model_gb, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2)
gb_pi_importances = pd.Series(gb_pi.importances_mean, index=columns)

# Collating data
models = ['Linear Regression', 'Decision Tree', 'Random Forest', 'Gradient Boosting']
data = [
    np.abs(importance_lr),
    importance_dt,
    importance_rf,
    importance_gb
]
feature_summary = pd.DataFrame(data, columns=columns, index=models)

pd.set_option('display.float_format', '{:0.4f}'.format)

fi_std = [
    lr_pi.importances_std,
    dt_pi.importances_std,
    rf_pi.importances_std,
    gb_pi.importances_std
]

tmp = pd.DataFrame(fi_std, index=models, columns=feature_summary.columns)
fi_mean = feature_summary.T
fi_std = tmp.T

# Plotting
fig, ax = plt.subplots(figsize=(24, 6))
fi_mean.plot.bar(yerr=fi_std, ax=ax, logy=True, grid=True)
ax.set_title("Feature importances using permutation on full model")
ax.set_ylabel("Mean accuracy decrease")
fig.tight_layout()
plt.show()

pd.DataFrame(fi_mean.mean(axis=1).sort_values(ascending=False), columns=['Mean'])

"""#SHAP Summary Plot without SD"""

!pip install shap

import shap

# Replace numeric labels with meaningful labels
class_labels = {0: "Not Damaged", 1: "Damaged", 2: "Destroyed"}
y_test_labels = y_test.map(class_labels)

# Convert the 'DAMAGE' column to integer type
y_train = y_train.astype(int)
y_test = y_test.astype(int)

# Fit the Random Forest model
model_rf = RandomForestClassifier(random_state=666)
model_rf.fit(X_train, y_train)

# Calculate SHAP values using TreeExplainer
explainer_rf = shap.TreeExplainer(model_rf)
shap_values_rf = explainer_rf.shap_values(X_test)

# Combine SHAP values for all classes in one summary plot
shap.summary_plot(shap_values_rf, X_test, class_names=list(class_labels.values()))

"""#SHAP with SD"""

import shap
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Data imputation
imputer = KNNImputer(n_neighbors=1)
imp_X = imputer.fit_transform(df)
df_X_imp = pd.DataFrame(imp_X, columns=df.columns)

# Data splitting
X = df_X_imp.drop('Damage', axis=1)
y = df_X_imp['Damage']
columns = X.columns

# Apply standard scaling to input features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)


# Replace this part with your actual data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Replace numeric labels with meaningful labels
class_labels = {0: "Not Damaged", 1: "Damaged", 2: "Destroyed"}
y_test_labels = y_test.map(class_labels)

# Fit the Random Forest model
model_rf = RandomForestClassifier(random_state=666)
model_rf.fit(X_train, y_train)

# Calculate SHAP values using TreeExplainer
explainer_rf = shap.TreeExplainer(model_rf)
shap_values_rf = explainer_rf.shap_values(X_test)

# Normalize SHAP values by the standard deviation
shap_values_rf_normalized = [shap_values_rf_class / shap_values_rf_class.std(axis=0)
                              for shap_values_rf_class in shap_values_rf]

# Combine SHAP values for all classes in one summary plot with consistent coloring
shap.summary_plot(shap_values_rf_normalized, X_test, class_names=list(class_labels.values()))

"""#Joint PDF"""

df

import seaborn as sns
import matplotlib.pyplot as plt

# Assuming 'df' is your DataFrame containing the dataset
# 'columns' is the list of features you want to include in the joint PDF

# Data split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=123, stratify=y)

# Specify the columns to be used for training
selected_columns = ['RoofConstruction', 'Eaves', 'VentScreen', 'ExteriorSiding', 'WindowPane', 'Deck/PorchOnGrade', 'Deck/PorchElevated', 'PatioCover', 'Fence', 'Distance']

X_train = X_train[selected_columns]
X_test = X_test[selected_columns]

# Combine features and target variable in a single DataFrame
df_selected = pd.concat([X_train, y_train], axis=1)

# Create a pairplot with scatterplots and histograms
sns.pairplot(df_selected, hue='Damage', diag_kind='kde', height=2)
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Increase figure size and set style
plt.figure(figsize=(12, 10))
sns.set(style="ticks")

# Specify the columns to be used for training
selected_columns = ['RoofConstruction', 'Eaves', 'VentScreen', 'ExteriorSiding', 'WindowPane', 'Deck/PorchOnGrade', 'Deck/PorchElevated', 'PatioCover', 'Fence', 'Distance']

# Combine features and target variable in a single DataFrame
df_selected = pd.concat([X_train[selected_columns], y_train], axis=1)

# Create a pairplot with scatterplots and histograms
pairplot = sns.pairplot(df_selected, hue='Damage', diag_kind='kde', height=2, palette='husl', markers=["o", "s"], plot_kws={'alpha': 0.5})

# Set a title
pairplot.fig.suptitle("Pairplot for Joint PDF", y=1.02, fontsize=16)

# Adjust layout
plt.tight_layout()
plt.show()