{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cc115ab-9c6b-4cb8-acd1-005ae72dd299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('default')\n",
    "plt_params = {\n",
    "    ## math font settings\n",
    "    \"text.usetex\": False,\n",
    "    \"mathtext.fontset\" : \"cm\",        \n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": \"Helvetica\",\n",
    "    \"text.latex.preamble\": \"\".join([r\"\\usepackage{amsmath}\", \n",
    "                                    r\"\\usepackage{amssymb}\"]),\n",
    "    \n",
    "    ## graph settings\n",
    "    \"font.size\" : 12,         ## general font size\n",
    "    \"axes.labelsize\": 12,     ## fontsize of the axes labels\n",
    "    \"xtick.labelsize\" : 12,\n",
    "    \"ytick.labelsize\" : 12,     \n",
    "    \"legend.fontsize\" : 12,\n",
    "    \"figure.figsize\": [5.5, 4.5],\n",
    "    \n",
    "    \"axes.linewidth\" : 1,\n",
    "    \"xtick.minor.visible\" : False,\n",
    "    \"ytick.minor.visible\" : False,\n",
    "    \n",
    "    \"xtick.major.size\" : 6,    \n",
    "    \"xtick.minor.size\" : 3,    \n",
    "    \"ytick.major.size\" : 6,    \n",
    "    \"ytick.minor.size\" : 3,    \n",
    "    \"xtick.major.width\" : 1,\n",
    "    \"xtick.minor.width\" : 1,\n",
    "    \"ytick.major.width\" : 1,\n",
    "    \"ytick.minor.width\" : 1,\n",
    "    \"xtick.direction\" : \"in\",\n",
    "    \"ytick.direction\" : \"in\"\n",
    "}\n",
    "mpl.rcParams.update(plt_params)\n",
    "\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "from utils.directory_structure import DATA_DIR, OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b94f6525-87bb-4216-a0b1-7fdb2991c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(est_dict):\n",
    "    MODEL_TYPE = est_dict[\"MODEL_TYPE\"]\n",
    "    MODEL_VERSION = est_dict[\"MODEL_VERSION\"]\n",
    "    MODEL_DIR = os.path.join(OUTPUT_DIR, MODEL_TYPE)\n",
    "    ML_MODEL_NAME = \"{}_{}_using_{}_features.pkl\".format(MODEL_TYPE, MODEL_VERSION, est_dict[\"FEATURE_TYPE\"])\n",
    "    \n",
    "    with open(os.path.join(MODEL_DIR, ML_MODEL_NAME), \"rb\") as file:\n",
    "        model = pickle.load(file)\n",
    "    return model\n",
    "\n",
    "def get_data(est_dict):\n",
    "    \n",
    "    case_name = est_dict[\"DATA_CASE\"]\n",
    "    task_type = est_dict[\"TASK_TYPE\"]\n",
    "    \n",
    "    if est_dict[\"WEIGHTED_CLASSES\"] is True:\n",
    "        postfix_name = \"lbe_targets\"\n",
    "    else:\n",
    "        postfix_name = \"ohe_targets\"\n",
    "\n",
    "    if est_dict[\"ENCODE_DATA\"]:\n",
    "        fname = os.path.join(OUTPUT_DIR, f\"{case_name}_{postfix_name}_train_test_num_ready_data_{task_type}.pkl\")\n",
    "    else:\n",
    "        fname = os.path.join(OUTPUT_DIR, f\"{case_name}_{postfix_name}_train_test_cat_ready_data_{task_type}.pkl\")\n",
    "\n",
    "    with open(fname, \"rb\") as file:\n",
    "        data_dict = pickle.load(file)\n",
    "        \n",
    "    return data_dict\n",
    "\n",
    "def model_proba(x):\n",
    "    return lr_be.predict_proba(x)[:, 1]\n",
    "\n",
    "def model_log_odds(x):\n",
    "    p = lr_be.predict_log_proba(x)\n",
    "    return p[:, 1] - p[:, 0]\n",
    "\n",
    "def treat_encoded_shap_vals(sv, X, data_dict):\n",
    "    shap_values = sv\n",
    "    # reconstruct the original dataset before encoding\n",
    "    X_cat_cols = data_dict[\"X_encoder\"].get_feature_names_out().tolist()\n",
    "    X_num_cols = ['yearbuilt_scaled', 'ssd_scaled', 'ember_scaled', 'flame_scaled', 'vsd_scaled', 'x_scaled', 'y_scaled'] \n",
    "    \n",
    "    X_cat_original = data_dict[\"X_encoder\"].inverse_transform(X[X_cat_cols])\n",
    "    X_cat_original = pd.DataFrame(X_cat_original, columns=data_dict[\"X_encoder\"].feature_names_in_)\n",
    "    X_num_original = X.loc[:, X_num_cols].reset_index().drop([\"index\"], axis=1)\n",
    "    X_original = X_cat_original.join(X_num_original)\n",
    "    feature_names = X_cat_original.columns\n",
    "\n",
    "    # get number of unique classes within each categorical data\n",
    "    n_categories = []\n",
    "    for f in feature_names[:-1]:\n",
    "        n = X_cat_original[f].nunique()\n",
    "        n_categories.append(n)\n",
    "\n",
    "    # separating the shap values for categorical and numerical data\n",
    "    # this part needs to be done according to the order of the \n",
    "    # features in axis=1.\n",
    "    shap_values_cat = shap_values.values[:, :-len(X_num_cols)]\n",
    "    shap_values_num = shap_values.values[:, -len(X_num_cols):]\n",
    "\n",
    "    # replace the aggregated shap values for catgorical features\n",
    "    new_shap_values_cat = []\n",
    "    for values in shap_values_cat:        \n",
    "        values_split = np.split(values , np.cumsum(n_categories))\n",
    "        values_sum = [sum(vs) for vs in values_split]\n",
    "        new_shap_values_cat.append(values_sum)\n",
    "        \n",
    "    new_shap_values_cat = np.array(new_shap_values_cat)\n",
    "    new_shape_values = np.hstack((new_shap_values_cat, shap_values_num))\n",
    "    shap_values.values = new_shape_values\n",
    "    shap_values.data = X_original.values\n",
    "    shap_values.feature_names = feature_names.to_list() + X_num_cols\n",
    "    \n",
    "    return shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd5a1bd8-09b3-4465-a057-7f241c10cad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, \"estimator_params.json\")) as f:\n",
    "    est_dict = json.load(f)\n",
    "\n",
    "data_dict = get_data(est_dict)\n",
    "X_train, y_train = data_dict[\"X_train\"], data_dict[\"y_train\"]\n",
    "X_test, y_test = data_dict[\"X_test\"], data_dict[\"y_test\"]\n",
    "\n",
    "lr_gs = get_model(est_dict)[\"grid_search\"]\n",
    "lr_be = lr_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33f6e7c1-dcdb-476c-8f60-c1925fee3206",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 18001it [02:17, 122.80it/s]                                                                \n"
     ]
    }
   ],
   "source": [
    "explainer = shap.Explainer(lr_be.predict, masker=X_train)\n",
    "shap_values = explainer(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "773f778b-c1ec-4ad5-a383-888685c71914",
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing the function\n",
    "nsh = treat_encoded_shap_vals(shap_values, X_train, data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc0d25ad-8d17-4472-a83f-eac675f7a4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat_cols = data_dict[\"X_encoder\"].get_feature_names_out().tolist()\n",
    "X_num_cols = ['yearbuilt_scaled', 'ssd_scaled', 'ember_scaled', 'flame_scaled', 'vsd_scaled', 'x_scaled', 'y_scaled'] \n",
    "\n",
    "X_train_cat_original = data_dict[\"X_encoder\"].inverse_transform(X_train[X_cat_cols])\n",
    "X_train_cat_original = pd.DataFrame(X_train_cat_original, columns=data_dict[\"X_encoder\"].feature_names_in_)\n",
    "X_train_num_original = X_train.loc[:, X_num_cols].reset_index().drop([\"index\"], axis=1)\n",
    "X_train_original = X_train_cat_original.join(X_train_num_original)\n",
    "feature_names = X_train_cat_original.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f408161-77f7-41ff-a655-8e03170d9fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_cat = shap_values.values[:, :-7]\n",
    "shap_values_num = shap_values.values[:, -7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a44ca4de-3317-41a6-96ed-6bb6dd27ad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_categories = []\n",
    "for feat in feature_names[:-1]:\n",
    "    n = X_train_cat_original[feat].nunique()\n",
    "    n_categories.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9373a5ae-c0ed-41ad-9d00-98381dbd8949",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_shap_values_cat = []\n",
    "for values in shap_values_cat:\n",
    "    \n",
    "    #split shap values into a list for each feature\n",
    "    values_split = np.split(values , np.cumsum(n_categories))\n",
    "    \n",
    "    #sum values within each list\n",
    "    values_sum = [sum(l) for l in values_split]\n",
    "    \n",
    "    new_shap_values_cat.append(values_sum)\n",
    "    \n",
    "new_shap_values_cat = np.array(new_shap_values_cat)\n",
    "new_shape_values = np.hstack((new_shap_values_cat, shap_values_num))\n",
    "shap_values.values = new_shape_values\n",
    "shap_values.data = X_train_original.values\n",
    "shap_values.feature_names = feature_names.to_list() + X_num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66614078-b0ce-4832-86d8-4948c823ccb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6075149b-282d-4e95-a121-4f5132fe377b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d936e05f-eafa-45a8-a838-544ac8d497f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e5ed97-7845-40c1-81aa-9e5d75b6341b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db77db4b-5864-4548-bad7-024c338699bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbc0369-9d47-4478-881e-c3bb213949d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4c6d8c-8498-438e-8891-c6bbc1ebd574",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dins",
   "language": "python",
   "name": "dins"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
